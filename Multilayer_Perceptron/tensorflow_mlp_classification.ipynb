{
  "cells": [
    {
      "metadata": {
        "_uuid": "58a82c075d81e3119f134a0c5ef315e0780664d9"
      },
      "cell_type": "markdown",
      "source": "## Classification on MNIST dataset - Multilayer Perceptron in Tensorflow\n\nThis tutorial is taken from tensorFlow examples on [multiplayer perceptron](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py)."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n\nimport tensorflow as tf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting /tmp/data/train-images-idx3-ubyte.gz\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting /tmp/data/train-labels-idx1-ubyte.gz\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting /tmp/data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "learning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100\ndisplay_step = 1",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c81744878ba4e34fc9ec2e8afd2c0ecda06d56f2"
      },
      "cell_type": "code",
      "source": "# Parameters\nlearning_rate = 0.001\ntraining_epochs = 20\nbatch_size = 100\ndisplay_step = 1\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "340c02ab35d40f179f2a59a5e20ad3ff738b3b7d"
      },
      "cell_type": "code",
      "source": "# tf Graph input\nX = tf.placeholder(\"float\", [None, n_input])\nY = tf.placeholder(\"float\", [None, n_classes])\n\n# Store layers weight & bias\nweights = {\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n}\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c560198ec6ccdaf3a83e454862d28b00ca77190c"
      },
      "cell_type": "code",
      "source": "# Create model\ndef multilayer_perceptron(x):\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n    return out_layer",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b37e4d3feda8da380d3e59dc976b7943f26d641"
      },
      "cell_type": "code",
      "source": "# Construct model\nlogits = multilayer_perceptron(X)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6581d0013100b6f58a1a584c9ea39e9fbbae5455"
      },
      "cell_type": "code",
      "source": "# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n# Initializing the variables\ninit = tf.global_variables_initializer()",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9afbd3d9b5c7557b0a448ca1a00152666020a109"
      },
      "cell_type": "code",
      "source": "with tf.Session() as sess:\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n                                                            Y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n    print(\"Optimization Finished!\")\n    \n        # Test model\n    pred = tf.nn.softmax(logits)  # Apply softmax to logits\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n    print(\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch: 0001 cost=337.345721866\nEpoch: 0002 cost=96.886708646\nEpoch: 0003 cost=72.967135835\nEpoch: 0004 cost=58.330111575\nEpoch: 0005 cost=49.745431838\nEpoch: 0006 cost=44.667755928\nEpoch: 0007 cost=38.685530987\nEpoch: 0008 cost=35.704968432\nEpoch: 0009 cost=32.265088574\nEpoch: 0010 cost=31.324287697\nEpoch: 0011 cost=27.151894549\nEpoch: 0012 cost=26.171442509\nEpoch: 0013 cost=24.084461824\nEpoch: 0014 cost=24.340006135\nEpoch: 0015 cost=22.398592965\nEpoch: 0016 cost=21.200124836\nEpoch: 0017 cost=21.648926597\nEpoch: 0018 cost=20.215500966\nEpoch: 0019 cost=18.529479116\nEpoch: 0020 cost=18.545293932\nOptimization Finished!\nAccuracy: 0.8761\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0fd2cd7666524379273f43c5e8e6efb506c9abd"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}